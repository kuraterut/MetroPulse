### **Источники данных для проекта `MetroPulse`**

В вашей работе вы будете иметь дело с двумя основными источниками данных, которые моделируют реальную нагрузку IT-сервиса.

#### **Источник 1: OLTP База Данных (PostgreSQL)**

Это основная "боевая" база данных приложения. Она спроектирована по канонам 3-й нормальной формы для обеспечения целостности данных и быстрых транзакционных операций (OLTP - Online Transaction Processing).

**Схема OLTP Базы `metropulse_db`:**

    USERS 1:M RIDES : "совершает"
    USERS 1:M PAYMENTS : "производит"
    RIDES 1:1 PAYMENTS : "оплачивается"
    RIDES M:1 ROUTES : "по маршруту"
    ROUTES 1:M VEHICLES : "обслуживается"
    
    USERS {
        int user_id PK "ID пользователя"
        varchar name "Имя"
        varchar email "Email (уникальный)"
        timestamp created_at "Дата регистрации"
        varchar city "Город"
    }

    ROUTES {
        int route_id PK "ID маршрута"
        varchar route_number "Номер маршрута"
        varchar vehicle_type "Тип ТС ('bus', 'tram', 'metro')"
        decimal(10, 2) base_fare "Базовая стоимость проезда"
    }

    VEHICLES {
        int vehicle_id PK "ID транспортного средства"
        int route_id FK "ID маршрута"
        varchar license_plate "Гос. номер (для bus/tram)"
        int capacity "Вместимость"
    }

    RIDES {
        uuid ride_id PK "ID поездки"
        int user_id FK "ID пользователя"
        int route_id FK "ID маршрута"
        int vehicle_id FK "ID ТС"
        timestamp start_time "Время начала поездки"
        timestamp end_time "Время окончания поездки"
        decimal(10, 2) fare_amount "Сумма к оплате"
    }

    PAYMENTS {
        uuid payment_id PK "ID платежа"
        uuid ride_id FK "ID поездки"
        int user_id FK "ID пользователя"
        decimal(10, 2) amount "Сумма платежа"
        varchar payment_method "Метод ('card', 'sbp', 'wallet')"
        varchar status "Статус ('success', 'failed', 'pending')"
        timestamp created_at "Время создания платежа"
    }

**Описание таблиц и полей:**
*   **`USERS`**: Таблица пользователей.
    *   `user_id`: Первичный ключ.
    *   `email`: Уникальный идентификатор для входа.
    *   `city`: Важное измерение для аналитики.

*   **`ROUTES`**: Справочник маршрутов.
    *   `route_number`: Человекочитаемый номер.
    *   `vehicle_type`: 'bus', 'tram', 'metro'. Ключевая категоризация.
    *   `base_fare`: Базовая стоимость. Может меняться со временем (повод для SCD!).

*   **`VEHICLES`**: Справочник транспортных средств (ТС).
    *   Каждое ТС привязано к конкретному маршруту.

*   **`RIDES`**: Таблица фактов о поездках.
    *   `ride_id`: Первичный ключ.
    *   `start_time`, `end_time`: Ключевые временные метки для расчета длительности.
    *   `fare_amount`: Рассчитанная стоимость поездки. Может отличаться от `base_fare` из-за скидок или спец. тарифов.

*   **`PAYMENTS`**: Таблица транзакций.
    *   Связана и с пользователем, и с поездкой.
    *   `status`: Важно для анализа успешности платежей.

**Что с этими данными делать (задачи для DWH):**
*   Эти таблицы - ваш основной источник для **измерений (Dimensions)**, таких как Пользователь, Маршрут, Транспортное средство, Дата, Время.
*   Таблицы `RIDES` и `PAYMENTS` - это ваши основные источники для **таблиц фактов (Fact tables)**.
*   Вам нужно будет денормализовать эти данные, создавая широкие таблицы измерений и гранулярные таблицы фактов.
*   Данные из этой базы будут выгружаться в DWH периодически (например, раз в день) в рамках batch-процесса.

---

#### **Источник 2: Поток событий из Kafka**

Это real-time поток данных, поступающий от IoT-датчиков, установленных на каждом транспортном средстве.

**Топик Kafka:** `vehicle_positions`

**Формат сообщения:** JSON

**Пример сообщения:**
```json
{
  "event_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
  "vehicle_id": 101,
  "route_number": "А-72",
  "event_time": "2024-10-27T10:00:10Z",
  "coordinates": {
    "latitude": 55.7558,
    "longitude": 37.6173
  },
  "speed_kmh": 45.5,
  "passengers_estimated": 25
}
```

**Описание полей:**

*   `event_id`: Уникальный ID события.
*   `vehicle_id`: ID транспортного средства. **Ключ для соединения** с данными из OLTP-базы.
*   `route_number`: Номер маршрута (дублируется для удобства).
*   `event_time`: Точная временная метка события (UTC). **Ключевое поле для потоковой аналитики**.
*   `coordinates`: Гео-координаты.
*   `speed_kmh`: Мгновенная скорость.
*   `passengers_estimated`: Приблизительное количество пассажиров в салоне (по данным с датчиков).

**Что с этими данными делать:**
*   **Для Batch-аналитики (Этап 2):** Эти события должны быть собраны за день, агрегированы и загружены в DWH. Например, для создания фактов о средней скорости на маршруте, пройденном расстоянии, средней загруженности ТС. Это потребует создания отдельных таблиц фактов в DWH (например, `fact_vehicle_movement`).
*   **Для Real-time-аналитики (Этап 3, Вариант Б):** Этот поток будет обрабатываться "на лету" с помощью Flink для подсчета оперативных метрик (например, количество ТС на линии в данный момент).

---
